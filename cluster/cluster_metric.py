import os
import pandas as pd
import numpy as np
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.preprocessing import StandardScaler

def evaluate_cluster_quality(csv_folder, output_txt_path):
    report_lines = []

    for filename in sorted(os.listdir(csv_folder)):
        if not filename.endswith(".csv"):
            continue

        filepath = os.path.join(csv_folder, filename)
        df = pd.read_csv(filepath)

        if 'cluster_id' not in df.columns or 'reviewText' not in df.columns:
            report_lines.append(f"[{filename}] -> âŒ cluster_id ë˜ëŠ” reviewText ì»¬ëŸ¼ ì—†ìŒ\n")
            continue

        if df['cluster_id'].nunique() < 2:
            report_lines.append(f"[{filename}] -> âŒ í´ëŸ¬ìŠ¤í„° ìˆ˜ê°€ 2ê°œ ë¯¸ë§Œì´ë¼ í‰ê°€ ìƒëµ\n")
            continue

        # ì„ì‹œ ë²¡í„° (í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜)
        review_lengths = df['reviewText'].fillna("").str.len().values.reshape(-1, 1)
        vectors = StandardScaler().fit_transform(review_lengths)
        labels = df['cluster_id'].values

        try:
            sil_score = silhouette_score(vectors, labels)
            ch_score = calinski_harabasz_score(vectors, labels)
            db_score = davies_bouldin_score(vectors, labels)

            cluster_count = df['cluster_id'].nunique()
            total_reviews = len(df)

            report = (
                f"[{filename}]\n"
                f"  - í´ëŸ¬ìŠ¤í„° ìˆ˜:             {cluster_count}\n"
                f"  - ë¦¬ë·° ìˆ˜:                 {total_reviews}\n"
                f"  - Silhouette Score:        {sil_score:.4f}\n"
                f"  - Calinski-Harabasz Score: {ch_score:.2f}\n"
                f"  - Davies-Bouldin Score:    {db_score:.4f}\n"
            )

            # ğŸ” HDBSCANì´ë©´ ë…¸ì´ì¦ˆ ì •ë³´ ì¶”ê°€
            if "hdbscan" in filename.lower():
                noise_count = np.sum(labels == -1)
                noise_percent = (noise_count / total_reviews) * 100
                report += (
                    f"  - ë…¸ì´ì¦ˆ ìˆ˜:               {noise_count}\n"
                    f"  - ë…¸ì´ì¦ˆ í¼ì„¼íŠ¸:           {noise_percent:.2f}%\n"
                )

            report_lines.append(report + "\n")

        except Exception as e:
            report_lines.append(f"[{filename}] -> âŒ í‰ê°€ ì‹¤íŒ¨: {str(e)}\n")

    # ê²°ê³¼ ì €ì¥
    os.makedirs(os.path.dirname(output_txt_path), exist_ok=True)
    with open(output_txt_path, "w", encoding="utf-8") as f:
        f.writelines(report_lines)

    print(f"ğŸ“„ í´ëŸ¬ìŠ¤í„° í’ˆì§ˆ í‰ê°€ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_txt_path}")

# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    csv_folder = os.path.join(project_root, "results2")
    output_txt = os.path.join(project_root, "cluster/results2/emb2_cluster_metrics_report.txt")

    evaluate_cluster_quality(csv_folder, output_txt)
